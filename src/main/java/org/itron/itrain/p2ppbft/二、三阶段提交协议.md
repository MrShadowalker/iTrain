# 分布式一致性与二、三阶段提交协议

## 引言

在分布式系统中，为了保证数据的高可用,通常我们会将数据保留多个副本(replica), 这些副本会放置在不同的物理机器上。 为了对用户提供正确的 curd 等语意，我们需要保证这些放置在不同无力机器上的副本是一致的。

为了解决这种分布式一致性问题，提出了很多典型的协议和算法，比较著名的是二阶段提交协议，三阶段提交协议和 Paxos 算法。

## 分布式事务

在分布式系统中，各个节点之间在物理上相互独立，通过网络进行沟通和协调。 由于存在事务机制，可以保证每个独立节点上的数据操作可以满足 ACID。 但是，相互独立的节点之间无法准确地知道其他节点的事务执行情况。
所以从理论上来讲，两台机器无法达到一致的状态。 如果想让分布式部署的多台机器中的数据保持一致性，那么就要保证在所有节点数据的写操作，要么全部都执行，要么全部都不执行。
但是，一台机器在执行本地事务的时候无法知道其他机器中的本地事务的执行结果，所以它也就不知道本次事务到底应该 commit 还是 rollback。 所以，常规的解决办法就是引入一个“协调者”的组件来统一调度所有分布式节点的执行。

# 2PC（Two-phaseCommit）

## 二阶段提交

二阶段提交的算法思路可以概括为: 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。

二阶段是指:  第一阶段 - 请求阶段(表决阶段)     第二阶段 - 提交阶段(执行阶段)

(1) 请求阶段(表决)：

事务协调者通知每个参与者准备提交或取消事务，然后进入表决过程，参与者要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一种"万事俱备，只欠东风"的状态。

请求阶段，参与者将告知协调者自己的决策: 同意(事务参与者本地作业执行成功)或取消（本地作业执行故障）

以下是具体过程：

- 协调者向所有参与者发送事务内容，询问各个参与者是否可以提交事务，并等待所有参与者回复。
- 各参与者执行事务操作，将 Undo 和 Redo 信息记入事务日志中（此时不提交事务）。
- 如果参与者执行成功，则给协调者反馈可以成功提交的结果；如果执行失败，则给协调者反馈提交失败的结果。

(2) 提交阶段(执行):

在该阶段，写调整将基于第一个阶段的投票结果进行决策: 提交或取消

当且仅当所有的参与者同意提交事务，协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务

参与者在接收到协调者发来的消息后将执行响应的操作

以下是具体过程：

- 协调者向所有参与者发出开始提交事务的请求，即 Commit 请求。
- 参与者接收到 Commit 请求后，执行 Commit 请求。Commit 请求执行完毕后释放整个事务期间占用的资源。
- 参与者向协调者反馈 Commit 请求执行完成的消息。
- 协调者收到所有参与者反馈的消息后就完成了当前事务的提交。

当有任何一方参与者反馈提交失败的结果时，协调者就将事务中断。此时的协调者和参与者的处理逻辑如下：

- 协调者向所有参与者发出回滚请求，即 Rollback 请求。
- 参与者收到 Rollback 回滚请求后，使用第 1 阶段中的 Undo 信息执行回滚操作。Rollback 请求执行完毕后，同样需要释放整个事务期间占用的资源。
- 参与者向协调者反馈 Rollback 请求执行完成的消息。
- 协调者收到所有参与者反馈的消息后就完成当前事务的中断。

## 两阶段提交的缺点

1.同步阻塞问题。

执行过程中，所有参与节点都是事务阻塞型的。 当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。

2.单点故障。

由于协调者的重要性，一旦协调者发生故障，参与者会一直阻塞下去。 尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。
（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）

3.数据不一致。

在二阶段提交的阶段二中，当协调者向参与者发送 commit 请求之后，发生了局部网络异常或者在发送 commit 请求过程中协调者发生了故障， 这会导致只有一部分参与者接受到了 commit 请求，而在这部分参与者接到 commit
请求之后就会执行commit操作。 但是其他部分未接到 commit 请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据不一致性的现象。

## 两阶段提交无法解决的问题

当协调者出错，同时参与者也出错时，两阶段无法保证事务执行的完整性。 考虑协调者在发出 commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。
那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

# 3PC（Three-phaseCommit）

## 三阶段提交

三阶段提交协议在协调者和参与者中都引入超时机制，并且把两阶段提交协议的第一个阶段分成了两步: 询问，然后再锁资源，最后真正提交。

## 三阶段的执行

(1) canCommit 阶段

3PC 的 canCommit 阶段其实和 2PC 的准备阶段很像。协调者向参与者发送 commit 请求，参与者如果可以提交就返回 yes 响应，否则返回 no 响应。

(2) preCommit 阶段

协调者根据参与者 canCommit 阶段的响应来决定是否可以继续事务的 preCommit 操作。根据响应情况，有下面两种可能:

a) 协调者从所有参与者得到的反馈都是 yes:

那么进行事务的预执行，协调者向所有参与者发送 preCommit 请求，并进入 prepared 阶段。 参与者接收到 preCommit 请求后会执行事务操作，并将 undo 和 redo 信息记录到事务日志中。
如果一个参与者成功地执行了事务操作，则返回 ACK 响应，同时开始等待最终指令。

b) 协调者从所有参与者得到的反馈有一个是 No 或是等待超时之后协调者都没收到响应:

那么就要中断事务，协调者向所有的参与者发送 abort 请求。参与者在收到来自协调者的 abort 请求，或超时后仍未收到协调者请求，执行事务中断。

(3) doCommit 阶段

协调者根据参与者 preCommit 阶段的响应来决定是否可以继续事务的 doCommit 操作。根据响应情况，有下面两种可能:

a) 协调者从参与者得到了 ACK 的反馈:

协调者接收到参与者发送的 ACK 响应，那么它将从预提交状态进入到提交状态，并向所有参与者发送 doCommit 请求。 参与者接收到 doCommit 请求后，执行正式的事务提交，并在完成事务提交之后释放所有事务资源，并向协调者发送
haveCommitted 的 ACK 响应。 那么协调者收到这个 ACK 响应之后，完成任务。

b) 协调者从参与者没有得到 ACK 的反馈, 也可能是接收者发送的不是 ACK 响应，也可能是响应超时:

执行事务中断。

# 2PC vs 3PC

## 2PC和3PC

对于协调者(Coordinator)和参与者(Cohort)都设置了超时机制（在 2PC 中，只有协调者拥有超时机制，即如果在一定时间内没有收到 cohort 的消息则默认失败）。 在 2PC 的准备阶段和提交阶段之间，插入预提交阶段，使
3PC 拥有 CanCommit、PreCommit、DoCommit 三个阶段。 PreCommit 是一个缓冲，保证了在最后提交阶段之前各参与节点的状态是一致的。

三阶段提交是“非阻塞”协议。 三阶段提交在两阶段提交的第一阶段与第二阶段之间插入了一个准备阶段， 使得原先在两阶段提交中，参与者在投票之后，由于协调者发生崩溃或错误，
而导致参与者处于无法知晓是否提交或者中止的“不确定状态”所产生的可能相当长的延时的问题得以解决。
举例来说，假设有一个决策小组由一个主持人负责与多位组员以电话联络方式协调是否通过一个提案，对于两阶段提交来说，主持人收到一个提案请求，打电话跟每个组员询问是否通过并统计回复，然后将最后决定打电话通知各组员。
要是主持人在跟第一位组员通完电话后失忆，而第一位组员在得知结果并执行后老人痴呆，那么即使重新选出主持人，也没人知道最后的提案决定是什么，也许是通过，也许是驳回，不管大家选择哪一种决定，都有可能与第一位组员已执行过的真实决定不一致，老板就会不开心认为决策小组沟通有问题而解雇。
三阶段提交即是引入了另一个步骤，主持人打电话跟组员通知请准备通过提案，以避免没人知道真实决定而造成决定不一致的失业危机。

为什么能够解决二阶段提交的问题呢？ 回到刚刚提到的状况，在主持人通知完第一位组员请准备通过后两人意外失忆，即使没人知道全体在第一阶段的决定为何，全体决策组员仍可以重新协调过程或直接否决，不会有不一致决定而失业。
那么当主持人通知完全体组员请准备通过并得到大家的再次确定后进入第三阶段， 当主持人通知第一位组员请通过提案后两人意外失忆，这时候其他组员再重新选出主持人后，
仍可以知道目前至少是处于准备通过提案阶段，表示第一阶段大家都已经决定要通过了，此时便可以直接通过。

## 三阶段提交协议的缺点

如果进入 PreCommit 后，Coordinator 发出的是 abort 请求，假设只有一个 Cohort 收到并进行了 abort 操作， 而其他对于系统状态未知的 Cohort 会根据 3PC 选择继续
Commit，此时系统状态发生不一致性。

## 替代

目前还有一种重要的算法就是 Paxos 算法，Zookeeper 采用的就是 Paxos 算法的改进。